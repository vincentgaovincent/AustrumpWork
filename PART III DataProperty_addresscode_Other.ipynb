{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os    \n",
    "from dotenv  import load_dotenv\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import pandas as pd\n",
    "pd.options.display.max_colwidth = 600  # Set Full Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "suburb=\"Glen_Waverley\"\n",
    "suburb_search = \"glen-waverley-vic-3150\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "suburb=\"Mount_Waverley\"\n",
    "suburb_search = \"mount-waverley-vic-3149\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "suburb=\"Forest_Hill\"\n",
    "suburb_search = \"forest-hill-vic-3131\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "suburb=\"Vermont_South\"\n",
    "suburb_search = \"vermont-south-vic-3133\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "suburb=\"Mitcham\"\n",
    "suburb_search = \"mitcham-vic-3132\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "suburb=\"Vermont\"\n",
    "suburb_search = \"vermont-vic-3133\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(dotenv_path = Path(\"C:/Users/Leon/API_keys/.env\"))\n",
    "auproperty_api=os.getenv('auproperty_vincent2')\n",
    "type(auproperty_api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Authorization': 'Bearer eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJodHRwczovL2FwaTIuYXVwcm9wZXJ0eXJlcG9ydC5jb20vYXBpL2F1dGgiLCJpYXQiOjE2NTAwODE2OTcsImV4cCI6MTY1MDE2ODA5NywibmJmIjoxNjUwMDgxNjk3LCJqdGkiOiJzNWxjR1pTSXFHclpwZk1vIiwic3ViIjozNywicHJ2IjoiNDBhNDZkZjhmNTlkN2E5ZGVkZDc0NjRkZDI2NTNjOGIxNzE2ZTBiZCIsInBsYW4iOm51bGx9.6XDmvU7fNB0nurFui-5IhSjPFACmbscZ3jOoqzKedoY'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auth_url = 'https://api2.aupropertyreport.com/api/auth'\n",
    "\n",
    "auth_response = requests.post(auth_url, data = {\n",
    "                        'email':\"test@gmail.com\",\n",
    "                        'api_key':auproperty_api,\n",
    "                        })\n",
    "auth_token = auth_response.json() \n",
    "access_token = auth_token['data'][\"token\"]\n",
    "auth = {\"Authorization\":\"Bearer \" + access_token}\n",
    "auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overwrite, initiate second API key directly !!\n",
    "property_search_respond={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'address': '3/17 Hillcrest Avenue, Chadstone Vic 3148',\n",
       "  'code': 'unit-3-17-hillcrest-ave-chadstone-vic-3148',\n",
       "  'state': 'VIC',\n",
       "  'suburb': 'Chadstone',\n",
       "  'postcode': '3148'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "property_search_url = \"https://api2.aupropertyreport.com/api/property/search?q=3+17+hillcrest+ave+chadstone+vic+3148\"\n",
    "\n",
    "# GET Request\n",
    "property_search_request = requests.get(property_search_url,headers=auth,params={\"limit\":\"50\"})\n",
    "property_search_respond = property_search_request.json()\n",
    "property_search_respond"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exceed: {'message': 'You have exceeded your rate limit.', 'status_code': 429}\n",
    "\n",
    "Normal:  [{'address': '3/17 Hillcrest Avenue, Chadstone Vic 3148',\n",
    "  'code': 'unit-3-17-hillcrest-ave-chadstone-vic-3148',\n",
    "  'state': 'VIC',\n",
    "  'suburb': 'Chadstone',\n",
    "  'postcode': '3148'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 由于 address code search 的 respond 都是 list, 即使是空的，或者多个的，用来check rate-limit\n",
    "if isinstance(property_search_respond, dict):\n",
    "\n",
    "    auproperty_api=os.getenv('auproperty_vincent2')\n",
    "\n",
    "    auth_url = 'https://api2.aupropertyreport.com/api/auth'\n",
    "\n",
    "    auth_response = requests.post(auth_url, data = {\n",
    "                        'email':\"leon20130301@hotmail.com\",\n",
    "                        'api_key':os.getenv('auproperty_vincent'),\n",
    "                        })\n",
    "    auth_token = auth_response.json() \n",
    "    access_token = auth_token['data'][\"token\"]\n",
    "    auth = {\"Authorization\":\"Bearer \" + access_token}\n",
    "    print(auth) # 如果没有任何显示，则说明没有使用这个 API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Authorization': 'Bearer eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJodHRwczovL2FwaTIuYXVwcm9wZXJ0eXJlcG9ydC5jb20vYXBpL2F1dGgiLCJpYXQiOjE2NDkwNjQ5NDEsImV4cCI6MTY0OTE1MTM0MSwibmJmIjoxNjQ5MDY0OTQxLCJqdGkiOiJvRXllNWdzdjNVN0x5TGxjIiwic3ViIjozOSwicHJ2IjoiNDBhNDZkZjhmNTlkN2E5ZGVkZDc0NjRkZDI2NTNjOGIxNzE2ZTBiZCIsInBsYW4iOm51bGx9.OYpHlUFlkfIG1vgdr3052BR1tjf0y6Lc9wQk-MAl1RA'}\n"
     ]
    }
   ],
   "source": [
    "# 由于 address code search 的 respond 都是 list, 即使是空的，或者多个的，用来check rate-limit\n",
    "if isinstance(property_search_respond, dict):\n",
    "\n",
    "    auproperty_api=os.getenv('auproperty_vincent2')\n",
    "\n",
    "    auth_url = 'https://api2.aupropertyreport.com/api/auth'\n",
    "\n",
    "    auth_response = requests.post(auth_url, data = {\n",
    "                        'email':\"pengmel@hotmail.com\",\n",
    "                        'api_key':os.getenv('auproperty_vincent3'),\n",
    "                        })\n",
    "    auth_token = auth_response.json() \n",
    "    access_token = auth_token['data'][\"token\"]\n",
    "    auth = {\"Authorization\":\"Bearer \" + access_token}\n",
    "    print(auth) # 如果没有任何显示，则说明没有使用这个 API key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Suburb For Sale Properties: Days on the market"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create File:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame is written successfully to Excel File.\n"
     ]
    }
   ],
   "source": [
    "reset_df=pd.DataFrame()\n",
    "# create excel writer object\n",
    "writer=pd.ExcelWriter(f'Suburb_for_Sale_{suburb}.xlsx')\n",
    "# write dataframe to excel\n",
    "reset_df.to_excel(writer, index=False)\n",
    "# save the excel\n",
    "writer.save()\n",
    "print('DataFrame is written successfully to Excel File.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization: Loading saved data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 0 entries\n",
      "Empty DataFrameNone\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use r -- to avoid unicode error !\n",
    "filesaved_forsale_path=Path(rf'C:\\Users\\LEON\\test\\domain\\Suburb_for_Sale_{suburb}.xlsx')\n",
    "filesaved_forsale_df = pd.read_excel(filesaved_forsale_path, parse_dates=True)\n",
    "print(filesaved_forsale_df.info())\n",
    "filesaved_forsale_df.tail(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating: 注意：之前 for sale 之後不 for sale 也會被記錄："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display What is Currently On the Market -- duplicates removed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame is written successfully to Excel File.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 33 entries, 0 to 32\n",
      "Data columns (total 19 columns):\n",
      "state             33 non-null object\n",
      "address           33 non-null object\n",
      "suburb_code       33 non-null object\n",
      "suburb_name       33 non-null object\n",
      "postcode          33 non-null object\n",
      "image             33 non-null object\n",
      "type              33 non-null object\n",
      "bed               33 non-null int64\n",
      "bath              33 non-null int64\n",
      "car               33 non-null int64\n",
      "lat               33 non-null float64\n",
      "lng               33 non-null float64\n",
      "land              33 non-null object\n",
      "list_date         33 non-null object\n",
      "list_price        33 non-null object\n",
      "days_on_market    33 non-null int64\n",
      "gnaf_pid          33 non-null object\n",
      "pu_id             33 non-null int64\n",
      "agent_code        33 non-null object\n",
      "dtypes: float64(2), int64(5), object(12)\n",
      "memory usage: 5.2+ KB\n",
      "None\n",
      "---------------------------------------------\n",
      "Updated Entries: 33\n",
      "---------------------------------------------\n",
      "Check for duplication: 0\n"
     ]
    }
   ],
   "source": [
    "for_sale_url = f\"https://api2.aupropertyreport.com/api/suburb/{suburb_search}/buy\"\n",
    "# GET Request\n",
    "for_sale_request_1 = requests.get(for_sale_url,headers=auth,params={\"limit\":\"50\"})\n",
    "for_sale_respond_1 = for_sale_request_1.json()\n",
    "\n",
    "if \"message\" not in for_sale_respond_1:\n",
    "\n",
    "    # get total page number:\n",
    "    for_sale_pagesnum = for_sale_respond_1[\"data\"][\"buy\"][\"meta\"][\"pagination\"][\"total_pages\"]\n",
    "    # save the first call API data to dataframe:\n",
    "    for_sale_df = pd.DataFrame(for_sale_respond_1[\"data\"][\"buy\"]['data'])\n",
    "\n",
    "    for page_num in range(2,for_sale_pagesnum+1): # first entry saved, range not inclusive last\n",
    "        for_sale_url_2 = f\"https://api2.aupropertyreport.com/api/suburb/{suburb_search}/buy?page={page_num}\"\n",
    "        # GET Request\n",
    "        for_sale_request_2 = requests.get(for_sale_url_2,headers=auth,params={\"limit\":\"50\"})\n",
    "        for_sale_respond_2 = for_sale_request_2.json()\n",
    "        \n",
    "        if \"message\" not in for_sale_respond_2:\n",
    "            for_sale_temp_df = pd.DataFrame(for_sale_respond_2[\"data\"][\"buy\"]['data'])\n",
    "            for_sale_df = for_sale_df.append(for_sale_temp_df)\n",
    "        else:\n",
    "            print(\"ERROR IN RESPOND\")\n",
    "            break        \n",
    "     \n",
    "    for_sale_df = for_sale_df.drop_duplicates(\"address\",keep=\"last\")\n",
    "\n",
    "    for_sale_updated_df = filesaved_forsale_df.append(for_sale_df)\n",
    "    for_sale_updated_df = for_sale_updated_df.drop_duplicates(\"address\",keep=\"last\")\n",
    "\n",
    "    for_sale_num_duplication = for_sale_updated_df[\"address\"].duplicated().sum()\n",
    "    \n",
    "    for_sale_updated_df=for_sale_updated_df.sort_values(by='days_on_market', ascending=True)\n",
    "\n",
    "    # create excel writer object\n",
    "    writer=pd.ExcelWriter(f'Suburb_for_Sale_{suburb}.xlsx')\n",
    "    # write dataframe to excel\n",
    "    for_sale_updated_df.to_excel(writer, index=False)\n",
    "    # save the excel\n",
    "    writer.save()\n",
    "    print('DataFrame is written successfully to Excel File.')\n",
    "    print(for_sale_updated_df.info())\n",
    "    print(\"---------------------------------------------\")\n",
    "    print(f\"Updated Entries: {len(for_sale_updated_df)-len(filesaved_forsale_df)}\")\n",
    "    print(\"---------------------------------------------\")\n",
    "    print(f\"Check for duplication: {for_sale_num_duplication}\")\n",
    "        \n",
    "else:   \n",
    "    print(\"ERROR IN RESPOND\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Duplication:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PS: 非常注意：首次測試發現\n",
    "\n",
    "1) Address available on request -- 即使是不同的，也可以drop 因爲沒有地址；此處是 公寓\n",
    "\n",
    "2) 發現，極少 property 被反復 list,\n",
    "\n",
    "3) 發現，這些記錄 是按時間順序，從近到遠排列，\n",
    "\n",
    "Decision:\n",
    "\n",
    "因爲 我們是往後面 append, 所以 使用 df.drop_duplicates(\"address\", keep=\"last\"), 即後面出現的唯一，其他前面的是重複的，drop掉。\n",
    "\n",
    "而且，測試中發現，最近期的只是前面的刷新，只要還在list，更早期的記錄更完整，比如 listing 價格。\n",
    "\n",
    "input output 都需要 drop!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check input duplication:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filesaved_forsale_df[\"address\"].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filesaved_df[filesaved_df[\"address\"].duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check update duplication:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for_sale_df[\"address\"].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for_sale_df[for_sale_df[\"address\"].duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check output duplication:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for_sale_updated_df[\"address\"].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for_sale_updated_df[for_sale_updated_df[\"address\"].duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Suburb Auction Results: 半年範圍，但是沒有 20 Cherry 説明 並不完整 ！！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Sold',\n",
    "\n",
    "'Passed In',\n",
    "\n",
    "'Private Sale',\n",
    "\n",
    "'Withdrawn Prior To Auction',"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization: Loading saved data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 153 entries, 0 to 152\n",
      "Data columns (total 13 columns):\n",
      "address        153 non-null object\n",
      "agency         153 non-null object\n",
      "bed            153 non-null int64\n",
      "id             153 non-null int64\n",
      "is_sold        153 non-null bool\n",
      "postcode       153 non-null int64\n",
      "price          153 non-null int64\n",
      "pu_id          104 non-null float64\n",
      "result         153 non-null object\n",
      "sold_date      153 non-null object\n",
      "state          153 non-null object\n",
      "suburb_name    153 non-null object\n",
      "type           153 non-null object\n",
      "dtypes: bool(1), float64(1), int64(4), object(7)\n",
      "memory usage: 14.6+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>agency</th>\n",
       "      <th>bed</th>\n",
       "      <th>id</th>\n",
       "      <th>is_sold</th>\n",
       "      <th>postcode</th>\n",
       "      <th>price</th>\n",
       "      <th>pu_id</th>\n",
       "      <th>result</th>\n",
       "      <th>sold_date</th>\n",
       "      <th>state</th>\n",
       "      <th>suburb_name</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>152</td>\n",
       "      <td>1203/52-54 Osullivan Rd</td>\n",
       "      <td>Grandstand Real Estate</td>\n",
       "      <td>2</td>\n",
       "      <td>421413380</td>\n",
       "      <td>True</td>\n",
       "      <td>3150</td>\n",
       "      <td>660000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Private Sale</td>\n",
       "      <td>2021-10-09</td>\n",
       "      <td>VIC</td>\n",
       "      <td>Glen Waverley</td>\n",
       "      <td>unit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     address                  agency  bed         id  is_sold  \\\n",
       "152  1203/52-54 Osullivan Rd  Grandstand Real Estate    2  421413380     True   \n",
       "\n",
       "     postcode   price  pu_id        result   sold_date state    suburb_name  \\\n",
       "152      3150  660000    NaN  Private Sale  2021-10-09   VIC  Glen Waverley   \n",
       "\n",
       "     type  \n",
       "152  unit  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use r -- to avoid unicode error !\n",
    "filesaved_auction_path=Path(rf'C:\\Users\\LEON\\test\\domain\\Auction_Result_{suburb}.xlsx')\n",
    "filesaved_auction_df = pd.read_excel(filesaved_auction_path, parse_dates=True)\n",
    "print(filesaved_auction_df.info())\n",
    "filesaved_auction_df.tail(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame is written successfully to Excel File.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 153 entries, 0 to 2\n",
      "Data columns (total 13 columns):\n",
      "address        153 non-null object\n",
      "agency         153 non-null object\n",
      "bed            153 non-null int64\n",
      "id             153 non-null int64\n",
      "is_sold        153 non-null bool\n",
      "postcode       153 non-null object\n",
      "price          153 non-null int64\n",
      "pu_id          104 non-null float64\n",
      "result         153 non-null object\n",
      "sold_date      153 non-null object\n",
      "state          153 non-null object\n",
      "suburb_name    153 non-null object\n",
      "type           153 non-null object\n",
      "dtypes: bool(1), float64(1), int64(3), object(8)\n",
      "memory usage: 15.7+ KB\n",
      "None\n",
      "---------------------------------------------\n",
      "Updated Entries: 0\n",
      "---------------------------------------------\n",
      "Check for duplication: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEON\\anaconda3\\envs\\quantenv\\lib\\site-packages\\pandas\\core\\frame.py:7123: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort,\n"
     ]
    }
   ],
   "source": [
    "auction_results_url_1 = f\"https://api2.aupropertyreport.com/api/suburb/{suburb_search}/auction-results\"\n",
    "# GET Request\n",
    "auction_result_request_1 = requests.get(auction_results_url_1,headers=auth,params={\"limit\":\"50\"})\n",
    "auction_result_respond_1 = auction_result_request_1.json()\n",
    "\n",
    "if \"message\" not in auction_result_respond_1:\n",
    "\n",
    "    # get total page number:\n",
    "    auction_result_pagesnum = auction_result_respond_1[\"data\"][\"auction_results\"][\"meta\"][\"pagination\"][\"total_pages\"]\n",
    "    # save the first call API data to dataframe:\n",
    "    auction_result_df = pd.DataFrame(auction_result_respond_1[\"data\"][\"auction_results\"]['data'])\n",
    "\n",
    "    for page_num in range(2,auction_result_pagesnum+1): # first entry saved, range not inclusive last\n",
    "        auction_results_url_2 = f\"https://api2.aupropertyreport.com/api/suburb/{suburb_search}/auction-results?page={page_num}\"\n",
    "        # GET Request\n",
    "        auction_result_request_2 = requests.get(auction_results_url_2,headers=auth,params={\"limit\":\"50\"})\n",
    "        auction_result_respond_2 = auction_result_request_2.json()\n",
    "\n",
    "        if \"message\" not in auction_result_respond_2:\n",
    "            auction_result_temp_df = pd.DataFrame(auction_result_respond_2[\"data\"][\"auction_results\"]['data'])\n",
    "            auction_result_df = auction_result_df.append(auction_result_temp_df)\n",
    "        else:\n",
    "            print(\"ERROR IN RESPOND\")\n",
    "            break   \n",
    "\n",
    "    if \"message\" not in auction_result_respond_2:            \n",
    "        auction_result_df = auction_result_df.drop_duplicates(\"id\",keep=\"last\")\n",
    "\n",
    "        auction_result_updated_df = filesaved_auction_df.append(auction_result_df)\n",
    "        auction_result_updated_df = auction_result_updated_df.drop_duplicates(\"id\",keep=\"last\")\n",
    "\n",
    "        auction_result_updated_df=auction_result_updated_df.sort_values(by='sold_date', ascending=False)\n",
    "\n",
    "        # create excel writer object\n",
    "        writer=pd.ExcelWriter(f'Auction_Result_{suburb}.xlsx')\n",
    "        # write dataframe to excel\n",
    "        auction_result_updated_df.to_excel(writer, index=False)\n",
    "\n",
    "        auction_result_num_duplication = auction_result_updated_df[\"id\"].duplicated().sum()\n",
    "\n",
    "        # save the excel\n",
    "        writer.save()\n",
    "        print('DataFrame is written successfully to Excel File.')\n",
    "        print(auction_result_updated_df.info())\n",
    "        print(\"---------------------------------------------\")\n",
    "        print(f\"Updated Entries: {len(auction_result_updated_df)-len(filesaved_auction_df)}\")\n",
    "        print(\"---------------------------------------------\")\n",
    "        print(f\"Check for duplication: {auction_result_num_duplication}\")\n",
    "    else: \n",
    "        print(\"ERROR IN RESPOND\")\n",
    "else:   \n",
    "    print(\"ERROR IN RESPOND\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Duplication:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PS: 非常注意： \n",
    "\n",
    "同一個地址可以重複，比如 auction pass-in了，但是後來 private sale了,\n",
    "\n",
    "但是， id 不會重複！\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filesaved_auction_df[\"address\"].duplicated().sum()\n",
    "# filesaved_auction_df[filesaved_auction_df[\"address\"].duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filesaved_auction_df[\"id\"].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filesaved_auction_df[filesaved_auction_df[\"id\"].duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Suburb Sold Properties: 含 20 cherry, 一年範圍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization: Loading saved data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 721 entries, 0 to 720\n",
      "Data columns (total 19 columns):\n",
      "state                 721 non-null object\n",
      "address               721 non-null object\n",
      "suburb_code           721 non-null object\n",
      "suburb_name           721 non-null object\n",
      "postcode              721 non-null int64\n",
      "image                 721 non-null object\n",
      "type                  721 non-null object\n",
      "bed                   721 non-null int64\n",
      "bath                  721 non-null int64\n",
      "car                   721 non-null int64\n",
      "lat                   721 non-null float64\n",
      "lng                   721 non-null float64\n",
      "land                  512 non-null float64\n",
      "sold_date             721 non-null object\n",
      "sold_price            721 non-null int64\n",
      "gnaf_pid              710 non-null object\n",
      "pu_id                 721 non-null int64\n",
      "agent_code            720 non-null object\n",
      "sold_price_display    584 non-null object\n",
      "dtypes: float64(3), int64(6), object(10)\n",
      "memory usage: 107.1+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>address</th>\n",
       "      <th>suburb_code</th>\n",
       "      <th>suburb_name</th>\n",
       "      <th>postcode</th>\n",
       "      <th>image</th>\n",
       "      <th>type</th>\n",
       "      <th>bed</th>\n",
       "      <th>bath</th>\n",
       "      <th>car</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>land</th>\n",
       "      <th>sold_date</th>\n",
       "      <th>sold_price</th>\n",
       "      <th>gnaf_pid</th>\n",
       "      <th>pu_id</th>\n",
       "      <th>agent_code</th>\n",
       "      <th>sold_price_display</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>VIC</td>\n",
       "      <td>2/3 Churcher Court</td>\n",
       "      <td>mount-waverley-vic-3149</td>\n",
       "      <td>Mount Waverley</td>\n",
       "      <td>3149</td>\n",
       "      <td>https://farm66.static.flickr.com/65535/51981657745_1457d97335.jpg</td>\n",
       "      <td>townhouse</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-37.894041</td>\n",
       "      <td>145.109133</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-04-03</td>\n",
       "      <td>1152000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39785529351</td>\n",
       "      <td>VIC13820</td>\n",
       "      <td>$1,122,000 - $1,176,000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    state             address              suburb_code     suburb_name  \\\n",
       "720   VIC  2/3 Churcher Court  mount-waverley-vic-3149  Mount Waverley   \n",
       "\n",
       "     postcode  \\\n",
       "720      3149   \n",
       "\n",
       "                                                                 image  \\\n",
       "720  https://farm66.static.flickr.com/65535/51981657745_1457d97335.jpg   \n",
       "\n",
       "          type  bed  bath  car        lat         lng  land   sold_date  \\\n",
       "720  townhouse    4     2    2 -37.894041  145.109133   NaN  2022-04-03   \n",
       "\n",
       "     sold_price gnaf_pid        pu_id agent_code       sold_price_display  \n",
       "720     1152000      NaN  39785529351   VIC13820  $1,122,000 - $1,176,000  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use r -- to avoid unicode error !\n",
    "filesaved_sold_path=Path(rf'C:\\Users\\LEON\\test\\domain\\Sold_Result_{suburb}.xlsx')\n",
    "filesaved_sold_df = pd.read_excel(filesaved_sold_path, parse_dates=True)\n",
    "print(filesaved_sold_df.info())\n",
    "filesaved_sold_df.tail(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame is written successfully to Excel File.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 722 entries, 0 to 0\n",
      "Data columns (total 19 columns):\n",
      "state                 722 non-null object\n",
      "address               722 non-null object\n",
      "suburb_code           722 non-null object\n",
      "suburb_name           722 non-null object\n",
      "postcode              722 non-null object\n",
      "image                 722 non-null object\n",
      "type                  722 non-null object\n",
      "bed                   722 non-null int64\n",
      "bath                  722 non-null int64\n",
      "car                   722 non-null int64\n",
      "lat                   722 non-null float64\n",
      "lng                   722 non-null float64\n",
      "land                  716 non-null object\n",
      "sold_date             722 non-null object\n",
      "sold_price            722 non-null int64\n",
      "gnaf_pid              722 non-null object\n",
      "pu_id                 722 non-null int64\n",
      "agent_code            721 non-null object\n",
      "sold_price_display    584 non-null object\n",
      "dtypes: float64(2), int64(5), object(12)\n",
      "memory usage: 112.8+ KB\n",
      "None\n",
      "---------------------------------------------\n",
      "Updated Entries: 1\n",
      "---------------------------------------------\n",
      "Check for duplication: 0\n"
     ]
    }
   ],
   "source": [
    "sold_results_url_1 = f\"https://api2.aupropertyreport.com/api/suburb/{suburb_search}/sold\"\n",
    "# GET Request\n",
    "sold_result_request_1 = requests.get(sold_results_url_1,headers=auth,params={\"limit\":\"50\"})\n",
    "sold_result_respond_1 = sold_result_request_1.json()\n",
    "\n",
    "if \"message\" not in sold_result_respond_1:\n",
    "    # get total page number:\n",
    "    sold_result_pagesnum = sold_result_respond_1[\"data\"][\"sold\"][\"meta\"][\"pagination\"][\"total_pages\"]\n",
    "    # save the first call API data to dataframe:\n",
    "    sold_result_df = pd.DataFrame(sold_result_respond_1[\"data\"][\"sold\"]['data'])\n",
    "\n",
    "    for page_num in range(2,sold_result_pagesnum+1): # first entry saved, range not inclusive last\n",
    "        sold_results_url_2 = f\"https://api2.aupropertyreport.com/api/suburb/{suburb_search}/sold?page={page_num}\"\n",
    "        # GET Request\n",
    "        sold_result_request_2 = requests.get(sold_results_url_2,headers=auth,params={\"limit\":\"50\"})\n",
    "        sold_result_respond_2 = sold_result_request_2.json()\n",
    "\n",
    "        if \"message\" not in sold_result_respond_2:\n",
    "            sold_result_temp_df = pd.DataFrame(sold_result_respond_2[\"data\"][\"sold\"]['data'])\n",
    "            sold_result_df = sold_result_df.append(sold_result_temp_df)\n",
    "        else:\n",
    "            print(\"ERROR IN RESPOND\")\n",
    "            break  \n",
    "\n",
    "    if \"message\" not in for_sale_respond_2:         \n",
    "        sold_result_df = sold_result_df.drop_duplicates(subset=[\"address\",\"sold_date\"],keep=\"last\")\n",
    "\n",
    "        sold_result_updated_df = filesaved_sold_df.append(sold_result_df)\n",
    "        sold_result_updated_df = sold_result_updated_df.drop_duplicates(subset=[\"address\",\"sold_date\"],keep=\"last\")\n",
    "\n",
    "        sold_result_updated_df=sold_result_updated_df.sort_values(by='sold_date', ascending=True)\n",
    "\n",
    "        # create excel writer object\n",
    "        writer=pd.ExcelWriter(f'Sold_Result_{suburb}.xlsx')\n",
    "        # write dataframe to excel\n",
    "        sold_result_updated_df.to_excel(writer, index=False)\n",
    "\n",
    "        sold_result_num_duplication = sold_result_updated_df.duplicated([\"address\",\"sold_date\"]).sum()\n",
    "        # save the excel\n",
    "        writer.save()\n",
    "        print('DataFrame is written successfully to Excel File.')\n",
    "        print(sold_result_updated_df.info())\n",
    "        print(\"---------------------------------------------\")\n",
    "        print(f\"Updated Entries: {len(sold_result_updated_df)-len(filesaved_sold_df)}\")\n",
    "        print(\"---------------------------------------------\")\n",
    "        print(f\"Check for duplication: {sold_result_num_duplication}\")\n",
    "        \n",
    "    else: \n",
    "        print(\"ERROR IN RESPOND\")\n",
    "else:   \n",
    "    print(\"ERROR IN RESPOND\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Duplication:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查 address:\n",
    "\n",
    "1) 確實有重複的\n",
    "\n",
    "2) 也有是 一年内 買了兩次 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(filesaved_sold_df.duplicated([\"address\",\"sold_date\"]).sum())\n",
    "# filesaved_sold_df[filesaved_sold_df.duplicated([\"address\",\"sold_date\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Suburb Sold Trend: 区域 一年範圍 過去每个月 中价位"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization: Loading saved data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13 entries, 0 to 12\n",
      "Data columns (total 22 columns):\n",
      "price_sum             13 non-null int64\n",
      "price_avg             13 non-null int64\n",
      "price_median          13 non-null int64\n",
      "standard_deviation    13 non-null int64\n",
      "price_min             13 non-null int64\n",
      "price_10th            13 non-null int64\n",
      "price_20th            13 non-null int64\n",
      "price_25th            13 non-null int64\n",
      "price_30th            13 non-null int64\n",
      "price_40th            13 non-null int64\n",
      "price_50th            13 non-null int64\n",
      "price_60th            13 non-null int64\n",
      "price_70th            13 non-null int64\n",
      "price_75th            13 non-null int64\n",
      "price_80th            13 non-null int64\n",
      "price_90th            13 non-null int64\n",
      "price_max             13 non-null int64\n",
      "num_all               13 non-null int64\n",
      "num_all_with_price    13 non-null int64\n",
      "start_date            13 non-null object\n",
      "end_date              13 non-null object\n",
      "growth                12 non-null float64\n",
      "dtypes: float64(1), int64(19), object(2)\n",
      "memory usage: 2.4+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price_sum</th>\n",
       "      <th>price_avg</th>\n",
       "      <th>price_median</th>\n",
       "      <th>standard_deviation</th>\n",
       "      <th>price_min</th>\n",
       "      <th>price_10th</th>\n",
       "      <th>price_20th</th>\n",
       "      <th>price_25th</th>\n",
       "      <th>price_30th</th>\n",
       "      <th>price_40th</th>\n",
       "      <th>...</th>\n",
       "      <th>price_70th</th>\n",
       "      <th>price_75th</th>\n",
       "      <th>price_80th</th>\n",
       "      <th>price_90th</th>\n",
       "      <th>price_max</th>\n",
       "      <th>num_all</th>\n",
       "      <th>num_all_with_price</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>growth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>531107980</td>\n",
       "      <td>1707743</td>\n",
       "      <td>1508500</td>\n",
       "      <td>926993</td>\n",
       "      <td>950000</td>\n",
       "      <td>1142500</td>\n",
       "      <td>1211000</td>\n",
       "      <td>1260000</td>\n",
       "      <td>1304000</td>\n",
       "      <td>1380000</td>\n",
       "      <td>...</td>\n",
       "      <td>1787000</td>\n",
       "      <td>1835000</td>\n",
       "      <td>1999000</td>\n",
       "      <td>2500000</td>\n",
       "      <td>11500000</td>\n",
       "      <td>446</td>\n",
       "      <td>311</td>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>2021-05-31</td>\n",
       "      <td>0.0640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>471514816</td>\n",
       "      <td>1648654</td>\n",
       "      <td>1417800</td>\n",
       "      <td>762532</td>\n",
       "      <td>853000</td>\n",
       "      <td>1120000</td>\n",
       "      <td>1200000</td>\n",
       "      <td>1230500</td>\n",
       "      <td>1282500</td>\n",
       "      <td>1340000</td>\n",
       "      <td>...</td>\n",
       "      <td>1712500</td>\n",
       "      <td>1804250</td>\n",
       "      <td>1902000</td>\n",
       "      <td>2500000</td>\n",
       "      <td>10100000</td>\n",
       "      <td>411</td>\n",
       "      <td>286</td>\n",
       "      <td>2020-05-01</td>\n",
       "      <td>2021-04-30</td>\n",
       "      <td>0.0127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>439257252</td>\n",
       "      <td>1620876</td>\n",
       "      <td>1400000</td>\n",
       "      <td>771293</td>\n",
       "      <td>853000</td>\n",
       "      <td>1108000</td>\n",
       "      <td>1190000</td>\n",
       "      <td>1210500</td>\n",
       "      <td>1250000</td>\n",
       "      <td>1327000</td>\n",
       "      <td>...</td>\n",
       "      <td>1658888</td>\n",
       "      <td>1788500</td>\n",
       "      <td>1888000</td>\n",
       "      <td>2350000</td>\n",
       "      <td>10100000</td>\n",
       "      <td>392</td>\n",
       "      <td>271</td>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>2021-03-31</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    price_sum  price_avg  price_median  standard_deviation  price_min  \\\n",
       "10  531107980    1707743       1508500              926993     950000   \n",
       "11  471514816    1648654       1417800              762532     853000   \n",
       "12  439257252    1620876       1400000              771293     853000   \n",
       "\n",
       "    price_10th  price_20th  price_25th  price_30th  price_40th  ...  \\\n",
       "10     1142500     1211000     1260000     1304000     1380000  ...   \n",
       "11     1120000     1200000     1230500     1282500     1340000  ...   \n",
       "12     1108000     1190000     1210500     1250000     1327000  ...   \n",
       "\n",
       "    price_70th  price_75th  price_80th  price_90th  price_max  num_all  \\\n",
       "10     1787000     1835000     1999000     2500000   11500000      446   \n",
       "11     1712500     1804250     1902000     2500000   10100000      411   \n",
       "12     1658888     1788500     1888000     2350000   10100000      392   \n",
       "\n",
       "    num_all_with_price  start_date    end_date  growth  \n",
       "10                 311  2020-06-01  2021-05-31  0.0640  \n",
       "11                 286  2020-05-01  2021-04-30  0.0127  \n",
       "12                 271  2020-04-01  2021-03-31     NaN  \n",
       "\n",
       "[3 rows x 22 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use r -- to avoid unicode error !\n",
    "filesaved_sub_soldtrend_path=Path(rf'C:\\Users\\LEON\\test\\domain\\Sold_Trend_{suburb}.xlsx')\n",
    "filesaved_sub_soldtrend_df = pd.read_excel(filesaved_sub_soldtrend_path, parse_dates=True)\n",
    "print(filesaved_sub_soldtrend_df.info())\n",
    "filesaved_sub_soldtrend_df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame is written successfully to Excel File.\n",
      "---------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 14 entries, 2022-03 to 0\n",
      "Data columns (total 22 columns):\n",
      "price_sum             14 non-null int64\n",
      "price_avg             14 non-null int64\n",
      "price_median          14 non-null int64\n",
      "standard_deviation    14 non-null int64\n",
      "price_min             14 non-null int64\n",
      "price_10th            14 non-null int64\n",
      "price_20th            14 non-null int64\n",
      "price_25th            14 non-null int64\n",
      "price_30th            14 non-null int64\n",
      "price_40th            14 non-null int64\n",
      "price_50th            14 non-null int64\n",
      "price_60th            14 non-null int64\n",
      "price_70th            14 non-null int64\n",
      "price_75th            14 non-null int64\n",
      "price_80th            14 non-null int64\n",
      "price_90th            14 non-null int64\n",
      "price_max             14 non-null int64\n",
      "num_all               14 non-null int64\n",
      "num_all_with_price    14 non-null int64\n",
      "start_date            14 non-null object\n",
      "end_date              14 non-null object\n",
      "growth                13 non-null object\n",
      "dtypes: int64(19), object(3)\n",
      "memory usage: 2.5+ KB\n",
      "None\n",
      "         price_sum  price_avg  price_median  standard_deviation  price_min  \\\n",
      "2022-03  458394589    1666890       1600000              412357     890000   \n",
      "2022-02  465147809    1661243       1580000              429066     890000   \n",
      "2022-01  464780997    1648160       1560000              436936     890000   \n",
      "2021-12  477860297    1642132       1560000              433966     890000   \n",
      "2021-11  445054876    1600917       1517500              407619     890000   \n",
      "\n",
      "         price_10th  price_20th  price_25th  price_30th  price_40th  ...  \\\n",
      "2022-03     1280000     1380000     1405000     1444400     1511200  ...   \n",
      "2022-02     1289000     1374800     1400000     1430000     1500000  ...   \n",
      "2022-01     1265380     1339400     1400000     1405300     1485000  ...   \n",
      "2021-12     1258500     1330000     1390000     1405000     1481500  ...   \n",
      "2021-11     1231400     1317000     1350850     1400000     1450000  ...   \n",
      "\n",
      "         price_70th  price_75th  price_80th  price_90th  price_max  num_all  \\\n",
      "2022-03     1760200     1808000     1850400     2249560    3968000      389   \n",
      "2022-02     1706900     1785000     1836000     2166800    3970000      401   \n",
      "2022-01     1700000     1784250     1834000     2149800    3970000      402   \n",
      "2021-12     1700000     1777250     1830000     2130000    3970000      411   \n",
      "2021-11     1675000     1717250     1785000     2013700    3970000      397   \n",
      "\n",
      "         num_all_with_price  start_date    end_date  growth  \n",
      "2022-03                 275  2021-04-01  2022-03-31  0.0127  \n",
      "2022-02                 280  2021-03-01  2022-02-28  0.0128  \n",
      "2022-01                 282  2021-02-01  2022-01-31       0  \n",
      "2021-12                 291  2021-01-01  2021-12-31   0.028  \n",
      "2021-11                 278  2020-12-01  2021-11-30  0.0117  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "---------------------------------------------\n",
      "Check for duplication: 0\n"
     ]
    }
   ],
   "source": [
    "sub_sold_trend_url = f\"https://api2.aupropertyreport.com/api/suburb/{suburb_search}/sold-trend-data\"\n",
    "\n",
    "# GET Request\n",
    "sub_sold_trend_request = requests.get(sub_sold_trend_url,headers=auth,params={\"limit\":\"50\"})\n",
    "sub_sold_trend_respond = sub_sold_trend_request.json()\n",
    "\n",
    "if \"message\" not in sub_sold_trend_respond:\n",
    "\n",
    "    # save the first call API data to dataframe:\n",
    "    sub_sold_trend_df = pd.DataFrame.from_dict(sub_sold_trend_respond[\"data\"][\"sold_trend_data\"]['data'][\"trend_list\"],orient='index')\n",
    "    sub_sold_updated_df = filesaved_sub_soldtrend_df.append(sub_sold_trend_df)\n",
    "\n",
    "    sub_sold_updated_df = sub_sold_updated_df.drop_duplicates(subset=[\"start_date\",\"end_date\"],keep=\"last\")\n",
    "    sub_sold_num_duplication = sub_sold_updated_df.duplicated([\"start_date\",\"end_date\"]).sum()\n",
    "\n",
    "    sub_sold_updated_df=sub_sold_updated_df.sort_values(by='start_date', ascending=False)\n",
    "\n",
    "    # create excel writer object\n",
    "    writer=pd.ExcelWriter(f'Sold_Trend_{suburb}.xlsx')\n",
    "    # write dataframe to excel\n",
    "    sub_sold_updated_df.to_excel(writer, index=False)\n",
    "    # save the excel\n",
    "    writer.save()\n",
    "    print('DataFrame is written successfully to Excel File.')\n",
    "    print(\"---------------------------------------------\")\n",
    "    print(sub_sold_updated_df.info())\n",
    "    print(sub_sold_updated_df.head())\n",
    "    print(\"---------------------------------------------\")\n",
    "    print(f\"Check for duplication: {sub_sold_num_duplication}\")\n",
    "\n",
    "else:   \n",
    "    print(\"ERROR IN RESPOND\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Reports:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suburb ABS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nabs_url = f\"https://api2.aupropertyreport.com/api/suburb/{suburb_search}/abs-data\"\\n\\n# GET Request\\nabs_request = requests.get(abs_url,headers=auth,params={\"limit\":\"50\"})\\nabs_respond=abs_request.json()\\nabs_respond\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "abs_url = f\"https://api2.aupropertyreport.com/api/suburb/{suburb_search}/abs-data\"\n",
    "\n",
    "# GET Request\n",
    "abs_request = requests.get(abs_url,headers=auth,params={\"limit\":\"50\"})\n",
    "abs_respond=abs_request.json()\n",
    "abs_respond\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sate Auction Summary: 不保存數據！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from dateutil import relativedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 st 周末："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2022-04-09'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "today = datetime.datetime.now()\n",
    "start = today - datetime.timedelta((today.weekday() + 1) % 7)\n",
    "sat = start + relativedelta.relativedelta(weekday=relativedelta.SA(-1))\n",
    "sat = sat.strftime(\"%Y-%m-%d\")\n",
    "sat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 nd 周末："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2022-04-02'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat2 = start + relativedelta.relativedelta(weekday=relativedelta.SA(-2))\n",
    "sat2 = sat2.strftime(\"%Y-%m-%d\")\n",
    "sat2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 年前，同樣星期數："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2021-10-23'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat3 = start + relativedelta.relativedelta(weekday=relativedelta.SA(-25))\n",
    "sat3 = sat3.strftime(\"%Y-%m-%d\")\n",
    "sat3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2021-04-24'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat4 = start + relativedelta.relativedelta(weekday=relativedelta.SA(-51))\n",
    "sat4 = sat4.strftime(\"%Y-%m-%d\")\n",
    "sat4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2020-10-31'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat5 = start + relativedelta.relativedelta(weekday=relativedelta.SA(-76))\n",
    "sat5 = sat5.strftime(\"%Y-%m-%d\")\n",
    "sat5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2020-05-02'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat6 = start + relativedelta.relativedelta(weekday=relativedelta.SA(-102))\n",
    "sat6 = sat6.strftime(\"%Y-%m-%d\")\n",
    "sat6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2019-11-09'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat7 = start + relativedelta.relativedelta(weekday=relativedelta.SA(-127))\n",
    "sat7 = sat7.strftime(\"%Y-%m-%d\")\n",
    "sat7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2019-05-11'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat8 = start + relativedelta.relativedelta(weekday=relativedelta.SA(-153))\n",
    "sat8 = sat8.strftime(\"%Y-%m-%d\")\n",
    "sat8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2018-11-17'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat9 = start + relativedelta.relativedelta(weekday=relativedelta.SA(-178))\n",
    "sat9 = sat9.strftime(\"%Y-%m-%d\")\n",
    "sat9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2018-05-19'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat10 = start + relativedelta.relativedelta(weekday=relativedelta.SA(-204))\n",
    "sat10 = sat10.strftime(\"%Y-%m-%d\")\n",
    "sat10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2017-11-25'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat11 = start + relativedelta.relativedelta(weekday=relativedelta.SA(-229))\n",
    "sat11 = sat11.strftime(\"%Y-%m-%d\")\n",
    "sat11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2017-05-27'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat12 = start + relativedelta.relativedelta(weekday=relativedelta.SA(-255))\n",
    "sat12 = sat12.strftime(\"%Y-%m-%d\")\n",
    "sat12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_list=[sat,sat2,sat3,sat4,sat5,sat6,sat7,sat8,sat9,sat10,sat11,sat12]\n",
    "# state_list=[\"vic\", \"nsw\", \"qld\", \"sa\", \"wa\", \"act\", \"nt\", \"tas\"]\n",
    "state_list=[\"vic\", \"nsw\", \"qld\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2022-04-09',\n",
       " '2022-04-02',\n",
       " '2021-10-23',\n",
       " '2021-04-24',\n",
       " '2020-10-31',\n",
       " '2020-05-02',\n",
       " '2019-11-09',\n",
       " '2019-05-11',\n",
       " '2018-11-17',\n",
       " '2018-05-19',\n",
       " '2017-11-25',\n",
       " '2017-05-27']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果沒更新：\n",
    "\n",
    "{'message': 'get_class() expects parameter 1 to be object, null given',\n",
    " 'status_code': 500}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.aupropertyreport.com/auction-results/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': {'week': 14,\n",
       "  'state': 'VIC',\n",
       "  'auction_date': '2022-04-09',\n",
       "  'clearance_rate': 73.7,\n",
       "  'reported': 1027,\n",
       "  'sold_before_auction': 296,\n",
       "  'sold_at_auction': 452,\n",
       "  'sold_after_auction': 9,\n",
       "  'withdrawn': 39,\n",
       "  'passed_in': 231,\n",
       "  'sold': 757,\n",
       "  'unsold': 270,\n",
       "  'sum_price': 653007176,\n",
       "  'median_price': 995000,\n",
       "  'updated_at': '2022-04-09'}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "state_auction_summary_url = f\"https://api2.aupropertyreport.com/api/state/vic/auction-summary?date={sat}\"\n",
    "# GET Request\n",
    "state_auction_summary_request = requests.get(state_auction_summary_url,headers=auth,params={\"limit\":\"50\"})\n",
    "state_auction_summary_respond = state_auction_summary_request.json()\n",
    "state_auction_summary_respond\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warning ! Reset File !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame is written successfully to Excel File.\n"
     ]
    }
   ],
   "source": [
    "reset_df=pd.DataFrame()\n",
    "# create excel writer object\n",
    "writer=pd.ExcelWriter(f'State_Auction_Result.xlsx')\n",
    "# write dataframe to excel\n",
    "reset_df.to_excel(writer, index=False)\n",
    "# save the excel\n",
    "writer.save()\n",
    "print('DataFrame is written successfully to Excel File.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading File:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 0 entries\n",
      "Empty DataFrameNone\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use r -- to avoid unicode error !\n",
    "filesaved_state_auction_path=Path(rf'C:\\Users\\LEON\\test\\domain\\State_Auction_Result.xlsx')\n",
    "filesaved_state_auction_df = pd.read_excel(filesaved_state_auction_path, parse_dates=True)\n",
    "print(filesaved_state_auction_df.info())\n",
    "filesaved_state_auction_df.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame is written successfully to Excel File.\n",
      "---------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 35 entries, 0 to 34\n",
      "Data columns (total 15 columns):\n",
      "week                   35 non-null int64\n",
      "state                  35 non-null object\n",
      "auction_date           35 non-null object\n",
      "clearance_rate         35 non-null float64\n",
      "reported               35 non-null int64\n",
      "sold_before_auction    35 non-null int64\n",
      "sold_at_auction        35 non-null int64\n",
      "sold_after_auction     35 non-null int64\n",
      "withdrawn              35 non-null int64\n",
      "passed_in              35 non-null int64\n",
      "sold                   35 non-null int64\n",
      "unsold                 35 non-null int64\n",
      "sum_price              35 non-null int64\n",
      "median_price           35 non-null int64\n",
      "updated_at             35 non-null object\n",
      "dtypes: float64(1), int64(11), object(3)\n",
      "memory usage: 4.4+ KB\n",
      "None\n",
      "---------------------------------------------\n",
      "Check for duplication: 0\n"
     ]
    }
   ],
   "source": [
    "temp=[]\n",
    "for each_state in state_list:\n",
    "    for date in date_list:\n",
    "        state_auction_summary_url = f\"https://api2.aupropertyreport.com/api/state/{each_state}/auction-summary?date={date}\"\n",
    "        # GET Request\n",
    "        state_auction_summary_request = requests.get(state_auction_summary_url,headers=auth,params={\"limit\":\"50\"})\n",
    "        state_auction_summary_respond = state_auction_summary_request.json()\n",
    "        \n",
    "        if \"message\" not in state_auction_summary_respond and state_auction_summary_respond[\"data\"][\"clearance_rate\"]!=0: # skip 0\n",
    "            temp.append(state_auction_summary_respond[\"data\"])\n",
    "\n",
    "        else: \n",
    "            pass # 如果找不到就不記錄！！注意：不會記錄 0 ！！\n",
    "\n",
    "    state_auction_df=pd.DataFrame(temp)\n",
    "    \n",
    "filesaved_state_auction_df=filesaved_state_auction_df.append(state_auction_df)        \n",
    "\n",
    "filesaved_state_auction_df = filesaved_state_auction_df.drop_duplicates(subset=[\"auction_date\",\"state\"],keep=\"last\")\n",
    "num_duplication = filesaved_state_auction_df.duplicated([\"auction_date\",\"state\"]).sum()\n",
    "\n",
    "filesaved_state_auction_df=filesaved_state_auction_df.sort_values(by='auction_date', ascending=False)\n",
    "\n",
    "# create excel writer object\n",
    "writer=pd.ExcelWriter(f'State_Auction_Result.xlsx')\n",
    "# write dataframe to excel\n",
    "filesaved_state_auction_df.to_excel(writer, index=False)\n",
    "# save the excel\n",
    "writer.save()\n",
    "print('DataFrame is written successfully to Excel File.')\n",
    "print(\"---------------------------------------------\")\n",
    "print(filesaved_state_auction_df.info())\n",
    "print(\"---------------------------------------------\")\n",
    "print(f\"Check for duplication: {num_duplication}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>week</th>\n",
       "      <th>state</th>\n",
       "      <th>auction_date</th>\n",
       "      <th>clearance_rate</th>\n",
       "      <th>reported</th>\n",
       "      <th>sold_before_auction</th>\n",
       "      <th>sold_at_auction</th>\n",
       "      <th>sold_after_auction</th>\n",
       "      <th>withdrawn</th>\n",
       "      <th>passed_in</th>\n",
       "      <th>sold</th>\n",
       "      <th>unsold</th>\n",
       "      <th>sum_price</th>\n",
       "      <th>median_price</th>\n",
       "      <th>updated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>VIC</td>\n",
       "      <td>2022-04-09</td>\n",
       "      <td>73.7</td>\n",
       "      <td>1027</td>\n",
       "      <td>296</td>\n",
       "      <td>452</td>\n",
       "      <td>9</td>\n",
       "      <td>39</td>\n",
       "      <td>231</td>\n",
       "      <td>757</td>\n",
       "      <td>270</td>\n",
       "      <td>653007176</td>\n",
       "      <td>995000</td>\n",
       "      <td>2022-04-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>14</td>\n",
       "      <td>QLD</td>\n",
       "      <td>2022-04-09</td>\n",
       "      <td>94.4</td>\n",
       "      <td>36</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>34857000</td>\n",
       "      <td>1105000</td>\n",
       "      <td>2022-04-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>NSW</td>\n",
       "      <td>2022-04-09</td>\n",
       "      <td>73.4</td>\n",
       "      <td>552</td>\n",
       "      <td>250</td>\n",
       "      <td>152</td>\n",
       "      <td>3</td>\n",
       "      <td>83</td>\n",
       "      <td>64</td>\n",
       "      <td>405</td>\n",
       "      <td>147</td>\n",
       "      <td>583673113</td>\n",
       "      <td>1627000</td>\n",
       "      <td>2022-04-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>13</td>\n",
       "      <td>QLD</td>\n",
       "      <td>2022-04-02</td>\n",
       "      <td>78.2</td>\n",
       "      <td>55</td>\n",
       "      <td>17</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>43</td>\n",
       "      <td>12</td>\n",
       "      <td>50667000</td>\n",
       "      <td>1460000</td>\n",
       "      <td>2022-04-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>VIC</td>\n",
       "      <td>2022-04-02</td>\n",
       "      <td>76.5</td>\n",
       "      <td>911</td>\n",
       "      <td>237</td>\n",
       "      <td>455</td>\n",
       "      <td>5</td>\n",
       "      <td>43</td>\n",
       "      <td>171</td>\n",
       "      <td>697</td>\n",
       "      <td>214</td>\n",
       "      <td>567840802</td>\n",
       "      <td>981000</td>\n",
       "      <td>2022-04-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    week state auction_date  clearance_rate  reported  sold_before_auction  \\\n",
       "0     14   VIC   2022-04-09            73.7      1027                  296   \n",
       "24    14   QLD   2022-04-09            94.4        36                   14   \n",
       "12    14   NSW   2022-04-09            73.4       552                  250   \n",
       "25    13   QLD   2022-04-02            78.2        55                   17   \n",
       "1     13   VIC   2022-04-02            76.5       911                  237   \n",
       "\n",
       "    sold_at_auction  sold_after_auction  withdrawn  passed_in  sold  unsold  \\\n",
       "0               452                   9         39        231   757     270   \n",
       "24               20                   0          1          1    34       2   \n",
       "12              152                   3         83         64   405     147   \n",
       "25               26                   0          3          9    43      12   \n",
       "1               455                   5         43        171   697     214   \n",
       "\n",
       "    sum_price  median_price  updated_at  \n",
       "0   653007176        995000  2022-04-09  \n",
       "24   34857000       1105000  2022-04-09  \n",
       "12  583673113       1627000  2022-04-09  \n",
       "25   50667000       1460000  2022-04-02  \n",
       "1   567840802        981000  2022-04-02  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filesaved_state_auction_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weekly Vic Auction Summary: 保存數據！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from dateutil import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 141 entries, 0 to 140\n",
      "Data columns (total 15 columns):\n",
      "week                   141 non-null int64\n",
      "state                  141 non-null object\n",
      "auction_date           141 non-null object\n",
      "clearance_rate         141 non-null float64\n",
      "reported               141 non-null int64\n",
      "sold_before_auction    141 non-null int64\n",
      "sold_at_auction        141 non-null int64\n",
      "sold_after_auction     141 non-null int64\n",
      "withdrawn              141 non-null int64\n",
      "passed_in              141 non-null int64\n",
      "sold                   141 non-null int64\n",
      "unsold                 141 non-null int64\n",
      "sum_price              141 non-null int64\n",
      "median_price           141 non-null int64\n",
      "updated_at             141 non-null object\n",
      "dtypes: float64(1), int64(11), object(3)\n",
      "memory usage: 16.6+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>week</th>\n",
       "      <th>state</th>\n",
       "      <th>auction_date</th>\n",
       "      <th>clearance_rate</th>\n",
       "      <th>reported</th>\n",
       "      <th>sold_before_auction</th>\n",
       "      <th>sold_at_auction</th>\n",
       "      <th>sold_after_auction</th>\n",
       "      <th>withdrawn</th>\n",
       "      <th>passed_in</th>\n",
       "      <th>sold</th>\n",
       "      <th>unsold</th>\n",
       "      <th>sum_price</th>\n",
       "      <th>median_price</th>\n",
       "      <th>updated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>14</td>\n",
       "      <td>QLD</td>\n",
       "      <td>2021-04-10</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39</td>\n",
       "      <td>10</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>21852500</td>\n",
       "      <td>795000</td>\n",
       "      <td>2021-04-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     week state auction_date  clearance_rate  reported  sold_before_auction  \\\n",
       "140    14   QLD   2021-04-10           100.0        39                   10   \n",
       "\n",
       "     sold_at_auction  sold_after_auction  withdrawn  passed_in  sold  unsold  \\\n",
       "140               29                   0          0          0    39       0   \n",
       "\n",
       "     sum_price  median_price  updated_at  \n",
       "140   21852500        795000  2021-04-10  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use r -- to avoid unicode error !\n",
    "filesaved_state_auction_weekly_path=Path(rf'C:\\Users\\LEON\\test\\domain\\State_Auction_Result_VIC_Weekly.xlsx')\n",
    "filesaved_state_auction_weekly_df = pd.read_excel(filesaved_state_auction_weekly_path, parse_dates=True)\n",
    "print(filesaved_state_auction_weekly_df.info())\n",
    "filesaved_state_auction_weekly_df.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame is written successfully to Excel File.\n",
      "---------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 144 entries, 94 to 138\n",
      "Data columns (total 15 columns):\n",
      "week                   144 non-null int64\n",
      "state                  144 non-null object\n",
      "auction_date           144 non-null object\n",
      "clearance_rate         144 non-null float64\n",
      "reported               144 non-null int64\n",
      "sold_before_auction    144 non-null int64\n",
      "sold_at_auction        144 non-null int64\n",
      "sold_after_auction     144 non-null int64\n",
      "withdrawn              144 non-null int64\n",
      "passed_in              144 non-null int64\n",
      "sold                   144 non-null int64\n",
      "unsold                 144 non-null int64\n",
      "sum_price              144 non-null int64\n",
      "median_price           144 non-null int64\n",
      "updated_at             144 non-null object\n",
      "dtypes: float64(1), int64(11), object(3)\n",
      "memory usage: 18.0+ KB\n",
      "None\n",
      "---------------------------------------------\n",
      "Check for duplication: 0\n"
     ]
    }
   ],
   "source": [
    "temp=[]\n",
    "state_list_vic=[\"vic\", \"nsw\", \"qld\"]\n",
    "\n",
    "for each_state in state_list_vic:\n",
    "    for i in range(1,53):\n",
    "        today = datetime.datetime.now()\n",
    "        start = today - datetime.timedelta((today.weekday() + 1) % 7)\n",
    "        sat = start + relativedelta.relativedelta(weekday=relativedelta.SA(-i))\n",
    "        sat = sat.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        state_auction_summary_url = f\"https://api2.aupropertyreport.com/api/state/{each_state}/auction-summary?date={sat}\"\n",
    "        # GET Request\n",
    "        state_auction_summary_request = requests.get(state_auction_summary_url,headers=auth,params={\"limit\":\"50\"})\n",
    "        state_auction_summary_respond = state_auction_summary_request.json()\n",
    "\n",
    "        if \"message\" not in state_auction_summary_respond and \"data\" in state_auction_summary_respond and state_auction_summary_respond[\"data\"][\"clearance_rate\"]!=0: # skip 0:  \n",
    "            temp.append(state_auction_summary_respond[\"data\"])\n",
    "        else: \n",
    "            pass # 如果找不到就不記錄！！注意：不會記錄 0 ！！\n",
    "        \n",
    "    state_auction_df=pd.DataFrame(temp)\n",
    "\n",
    "   \n",
    "filesaved_state_auction_weekly_df=filesaved_state_auction_weekly_df.append(state_auction_df)        \n",
    "\n",
    "filesaved_state_auction_weekly_df = filesaved_state_auction_weekly_df.drop_duplicates(subset=[\"auction_date\",\"state\"],keep=\"last\")\n",
    "num_duplication = filesaved_state_auction_weekly_df.duplicated([\"auction_date\",\"state\"]).sum()\n",
    "filesaved_state_auction_weekly_df=filesaved_state_auction_weekly_df.sort_values(by='auction_date', ascending=False)\n",
    "\n",
    "# create excel writer object\n",
    "writer=pd.ExcelWriter(f'State_Auction_Result_VIC_Weekly.xlsx')\n",
    "# write dataframe to excel\n",
    "filesaved_state_auction_weekly_df.to_excel(writer, index=False)\n",
    "# save the excel\n",
    "writer.save()\n",
    "print('DataFrame is written successfully to Excel File.')\n",
    "print(\"---------------------------------------------\")\n",
    "print(filesaved_state_auction_weekly_df.info())\n",
    "print(\"---------------------------------------------\")\n",
    "print(f\"Check for duplication: {num_duplication}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': {'week': 15,\n",
       "  'state': 'QLD',\n",
       "  'auction_date': '2021-04-17',\n",
       "  'clearance_rate': 94.1,\n",
       "  'reported': 34,\n",
       "  'sold_before_auction': 13,\n",
       "  'sold_at_auction': 19,\n",
       "  'sold_after_auction': 0,\n",
       "  'withdrawn': 0,\n",
       "  'passed_in': 2,\n",
       "  'sold': 32,\n",
       "  'unsold': 2,\n",
       "  'sum_price': 30224201,\n",
       "  'median_price': 1178000,\n",
       "  'updated_at': '2021-04-17'}}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_auction_summary_respond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://api2.aupropertyreport.com/api/state/qld/auction-summary?date=2021-04-17'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_auction_summary_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nstate_auction_summary_url = f\"https://api2.aupropertyreport.com/api/state/qld/auction-summary?date=2022-01-22\"\\n# GET Request\\nstate_auction_summary_request = requests.get(state_auction_summary_url,headers=auth,params={\"limit\":\"50\"})\\nstate_auction_summary_respond = state_auction_summary_request.json()\\nstate_auction_summary_respond\\n'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "state_auction_summary_url = f\"https://api2.aupropertyreport.com/api/state/qld/auction-summary?date=2022-01-22\"\n",
    "# GET Request\n",
    "state_auction_summary_request = requests.get(state_auction_summary_url,headers=auth,params={\"limit\":\"50\"})\n",
    "state_auction_summary_respond = state_auction_summary_request.json()\n",
    "state_auction_summary_respond\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "197f7c05eca0eda9aa6a4e612037c516df5659297f389f7c2f572b328809f0da"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
